{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transferlearning in c:\\users\\kiit\\anaconda3\\envs\\healthenv\\lib\\site-packages (0.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transferlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model_path = \"../model/face_model\"\n",
    "model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from transferlearning import *\n",
    "import cv2\n",
    "import lime\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LIME_explanation(img,num_label,positive=False):\n",
    "    \n",
    "    img_name = img.split('/')[-1][:-4]\n",
    "    savedir = \"../lime_explanations/\"\n",
    "    savename_img = savedir+img_name+'_explained.jpg'\n",
    "    savename_heatmap = savedir+img_name+'_heatmap.jpg'\n",
    "    \n",
    "    img_ = cv2.imread(img)\n",
    "    img_ = cv2.cvtColor(img_,cv2.COLOR_BGR2RGB)\n",
    "    img_ = img_/255\n",
    "    img_ = np.expand_dims(img_,axis=0)\n",
    "    \n",
    "    model = tf.keras.models.load_model(\"../model/face_model\")\n",
    "    explainer = lime_image.LimeImageExplainer()\n",
    "    explanation = explainer.explain_instance(img_[0].astype('double'), model.predict, top_labels=int(num_label), hide_color=0, num_samples=100)\n",
    "\n",
    "    temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=positive, num_features=int(num_label), hide_rest=False)\n",
    "    explain_img = mark_boundaries(temp / 2 + 0.5, mask)\n",
    "    ind =  explanation.top_labels[0]\n",
    "\n",
    "    dict_heatmap = dict(explanation.local_exp[ind])\n",
    "    heatmap = np.vectorize(dict_heatmap.get)(explanation.segments) \n",
    "    \n",
    "    im1 = Image.fromarray((explain_img*255).astype(np.uint8))\n",
    "    im1.save(savename_img)\n",
    "    plt.imsave(savename_heatmap,heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09846eea5a514530a0464a31863833b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    img = \"../Test/1.jpg\"\n",
    "    label = 3\n",
    "    positive = False\n",
    "\n",
    "    get_LIME_explanation(img,label,positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f417e68ab344073a4124c65c22ab930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for &: 'Sequential' and 'bool'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m positive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../model/face_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m img_path, heatmap_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_LIME_explanation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 17\u001b[0m, in \u001b[0;36mget_LIME_explanation\u001b[1;34m(img, num_label, positive)\u001b[0m\n\u001b[0;32m     14\u001b[0m explainer \u001b[38;5;241m=\u001b[39m lime_image\u001b[38;5;241m.\u001b[39mLimeImageExplainer()\n\u001b[0;32m     15\u001b[0m explanation \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mexplain_instance(img_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdouble\u001b[39m\u001b[38;5;124m'\u001b[39m), model\u001b[38;5;241m.\u001b[39mpredict, top_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(num_label), hide_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m temp, mask \u001b[38;5;241m=\u001b[39m \u001b[43mexplanation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image_and_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexplanation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtop_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositive_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_label\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhide_rest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m explain_img \u001b[38;5;241m=\u001b[39m mark_boundaries(temp \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m, mask)\n\u001b[0;32m     19\u001b[0m ind \u001b[38;5;241m=\u001b[39m  explanation\u001b[38;5;241m.\u001b[39mtop_labels[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\healthenv\\lib\\site-packages\\lime\\lime_image.py:57\u001b[0m, in \u001b[0;36mImageExplanation.get_image_and_mask\u001b[1;34m(self, label, positive_only, negative_only, hide_rest, num_features, min_weight)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_exp:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel not in explanation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpositive_only\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnegative_only\u001b[49m:\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPositive_only and negative_only cannot be true at the same time.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     59\u001b[0m segments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msegments\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for &: 'Sequential' and 'bool'"
     ]
    }
   ],
   "source": [
    "img = \"C:\\\\Users\\\\KIIT\\Desktop\\\\WhatsApp Image.jpg\"\n",
    "label = 3\n",
    "positive = False\n",
    "\n",
    "model = tf.keras.models.load_model(\"../model/face_model\")\n",
    "img_path, heatmap_path = get_LIME_explanation(img, label, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Open the image file\n",
    "image = Image.open(\"C:\\\\Users\\\\KIIT\\\\Desktop\\\\WhatsApp Image.jpg\")\n",
    "\n",
    "# Resize the image\n",
    "new_size = (200, 200)\n",
    "resized_image = image.resize(new_size)\n",
    "\n",
    "# Save the resized image to a file\n",
    "resized_image.save(\"C:\\\\Users\\\\KIIT\\\\anaconda3\\\\resize\\\\image_resized.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (healthenv)",
   "language": "python",
   "name": "healthenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
